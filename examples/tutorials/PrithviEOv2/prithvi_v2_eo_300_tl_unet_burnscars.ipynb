{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bacc318390456b",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1. In colab: Go to \"Runtime\" -> \"Change runtime type\" -> Select \"T4 GPU\"\n",
    "2. Install TerraTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_4z81Fn9RET",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install terratorch==0.99.9 gdown tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a",
   "metadata": {
    "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import gdown\n",
    "import terratorch\n",
    "import albumentations\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule\n",
    "import warnings\n",
    "os.environ[\"TENSORBOARD_PROXY_URL\"]= os.environ[\"NB_PREFIX\"]+\"/proxy/6006/\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b65b8e7cd7d65",
   "metadata": {},
   "source": [
    "3. Download the dataset from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dw5-9A4A4OmI",
   "metadata": {
    "id": "dw5-9A4A4OmI",
    "jupyter": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('hls_burn_scars.tar.gz'):\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1yFDNlGqGPxkc9lh9l1O70TuejXAQYYtC\")\n",
    "\n",
    "if not os.path.isdir('hls_burn_scars/'):\n",
    "    !tar -xzvf hls_burn_scars.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494",
   "metadata": {
    "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494"
   },
   "source": [
    "## HLS Burn Scars Dataset\n",
    "\n",
    "Lets start with analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3",
   "metadata": {
    "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3"
   },
   "outputs": [],
   "source": [
    "dataset_path = Path('hls_burn_scars')\n",
    "!ls \"hls_burn_scars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84969a1f8bcae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"hls_burn_scars/data/\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc",
   "metadata": {
    "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc"
   },
   "outputs": [],
   "source": [
    "datamodule = terratorch.datamodules.GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    num_classes=2,\n",
    "\n",
    "    # Define dataset paths \n",
    "    train_data_root=dataset_path / 'data/',\n",
    "    train_label_data_root=dataset_path / 'data/',\n",
    "    val_data_root=dataset_path / 'data/',\n",
    "    val_label_data_root=dataset_path / 'data/',\n",
    "    test_data_root=dataset_path / 'data/',\n",
    "    test_label_data_root=dataset_path / 'data/',\n",
    "\n",
    "    # Define splits\n",
    "    train_split=dataset_path / 'splits/train.txt',\n",
    "    val_split=dataset_path / 'splits/val.txt',\n",
    "    test_split=dataset_path / 'splits/test.txt',\n",
    "    \n",
    "    img_grep='*_merged.tif',\n",
    "    label_grep='*.mask.tif',\n",
    "    \n",
    "    train_transform=[\n",
    "        albumentations.D4(), # Random flips and rotation\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    ],\n",
    "    val_transform=None,  # Using ToTensor() by default\n",
    "    test_transform=None,\n",
    "        \n",
    "    # Define standardization values\n",
    "    means=[\n",
    "      0.0333497067415863,\n",
    "      0.0570118552053618,\n",
    "      0.0588974813200132,\n",
    "      0.2323245113436119,\n",
    "      0.1972854853760658,\n",
    "      0.1194491422518656,\n",
    "    ],\n",
    "    stds=[\n",
    "      0.0226913556882377,\n",
    "      0.0268075602230702,\n",
    "      0.0400410984436278,\n",
    "      0.0779173242367269,\n",
    "      0.0870873883814014,\n",
    "      0.0724197947743781,\n",
    "    ],\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    "    # We use all six bands of the data, so we don't need to define dataset_bands and output_bands.\n",
    ")\n",
    "\n",
    "# Setup train and val datasets\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08644e71-d82f-426c-b0c1-79026fccb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datasets train split size\n",
    "train_dataset = datamodule.train_dataset\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7062ddc-a3b7-4378-898c-41abcdf2ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datasets validation split size\n",
    "val_dataset = datamodule.val_dataset\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc29b1698dc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a few samples\n",
    "val_dataset.plot(val_dataset[0])\n",
    "val_dataset.plot(val_dataset[6])\n",
    "val_dataset.plot(val_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79",
   "metadata": {
    "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79"
   },
   "outputs": [],
   "source": [
    "# checking datasets testing split size\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a30ddef8ed5a",
   "metadata": {},
   "source": [
    "# Fine-tune Prithvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
   "metadata": {
    "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"output/burnscars/checkpoints/\",\n",
    "    mode=\"max\",\n",
    "    monitor=\"val/Multiclass_Jaccard_Index\", # Variable to monitor\n",
    "    filename=\"best-{epoch:02d}\",\n",
    ")\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=1, # Deactivate multi-gpu because it often fails in notebooks\n",
    "    precision='bf16-mixed',  # Speed up training\n",
    "    num_nodes=1,\n",
    "    logger=True,  # Uses TensorBoard by default\n",
    "    max_epochs=1, # For demos\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, pl.callbacks.RichProgressBar()],\n",
    "    default_root_dir=\"output/burnscars\",\n",
    "    detect_anomaly=True,\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = terratorch.tasks.SemanticSegmentationTask(\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    model_args={\n",
    "        # Backbone\n",
    "        \"backbone\": \"prithvi_eo_v2_300\", # Model can be either prithvi_eo_v1_100, prithvi_eo_v2_300, prithvi_eo_v2_300_tl, prithvi_eo_v2_600, prithvi_eo_v2_600_tl\n",
    "        \"backbone_pretrained\": True,\n",
    "        \"backbone_num_frames\": 1, # 1 is the default value,\n",
    "        \"backbone_img_size\": 512,\n",
    "        \"backbone_bands\": [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "        # \"backbone_coords_encoding\": [], # use [\"time\", \"location\"] for time and location metadata\n",
    "        \n",
    "        # Necks \n",
    "        \"necks\": [\n",
    "            {\n",
    "                \"name\": \"SelectIndices\",\n",
    "                # \"indices\": [2, 5, 8, 11] # indices for prithvi_eo_v1_100\n",
    "                \"indices\": [5, 11, 17, 23] # indices for prithvi_eo_v2_300\n",
    "                # \"indices\": [7, 15, 23, 31] # indices for prithvi_eo_v2_600\n",
    "            },\n",
    "            {\"name\": \"ReshapeTokensToImage\",},\n",
    "            {\"name\": \"LearnedInterpolateToPyramidal\"}            \n",
    "        ],\n",
    "        \n",
    "        # Decoder\n",
    "        \"decoder\": \"UNetDecoder\",\n",
    "        \"decoder_channels\": [512, 256, 128, 64],\n",
    "        \n",
    "        # Head\n",
    "        \"head_dropout\": 0.1,\n",
    "        \"num_classes\": 2,\n",
    "    },\n",
    "    \n",
    "    loss=\"ce\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr=1e-4,\n",
    "    ignore_index=-1,\n",
    "    freeze_backbone=True, # Only to speed up fine-tuning\n",
    "    freeze_decoder=False,\n",
    "    plot_on_val=True,\n",
    "    class_names=['no burned', 'burned']  # optionally define class names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0ec00057c56dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff284062edfce308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5149dab-c18e-4194-aa9e-4a0ba244a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_path = \"output/burnscars/checkpoints/best-epoch=00.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29dc02-d1b3-4d80-98ef-60e4584bad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_and_visual_inspection(model,ckpt_path):\n",
    "\n",
    "    # let's run the model on the test set\n",
    "    trainer.test(model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "\n",
    "    # now we can use the model for predictions and plotting!\n",
    "    model = terratorch.tasks.SemanticSegmentationTask.load_from_checkpoint(\n",
    "        ckpt_path,\n",
    "        model_factory=model.hparams.model_factory,\n",
    "        model_args=model.hparams.model_args,\n",
    "    )\n",
    "    \n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(test_loader))\n",
    "        images = datamodule.aug(batch)\n",
    "        images = batch[\"image\"].to(model.device)\n",
    "        masks = batch[\"mask\"].numpy()\n",
    "    \n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs.output, dim=1).cpu().numpy()\n",
    "    \n",
    "    for i in range(4):\n",
    "        sample = {key: batch[key][i] for key in batch}\n",
    "        sample[\"prediction\"] = preds[i]\n",
    "        sample[\"image\"] = sample[\"image\"].cpu()\n",
    "        sample[\"mask\"] = sample[\"mask\"].cpu()\n",
    "        test_dataset.plot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af890844-88b1-4a33-a69c-95d2d7d3a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_and_visual_inspection(model, best_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c41c8-16ce-499e-a2ab-25cfcd5a6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_100_epoch_path = \"burnscars_best-epoch=69.ckpt\"\n",
    "\n",
    "if not os.path.isfile(best_ckpt_100_epoch_path):\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1jl1XfTVlDw8y7std8a1e-sU5LuiFyi_I\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaa496-8359-4acb-ab4a-836e667d026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_and_visual_inspection(model, best_ckpt_100_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54779ae510fefc8f",
   "metadata": {},
   "source": [
    "# Fine-tuning via CLI\n",
    "\n",
    "You might want to restart the session to free up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8e91384bb8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fine-tuning\n",
    "!terratorch fit -c prithvi_v2_eo_300_tl_unet_burnscars.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac095bd-86ab-4a81-8ad9-d6acd4f4577d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
