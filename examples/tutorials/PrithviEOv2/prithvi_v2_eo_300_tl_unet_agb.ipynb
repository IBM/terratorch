{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bacc318390456b",
   "metadata": {},
   "source": [
    "# Setup\n",
    "1. In colab: Go to \"Runtime\" -> \"Change runtime type\" -> Select \"T4 GPU\"\n",
    "2. Install TerraTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W_4z81Fn9RET",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install terratorch==0.99.9 gdown tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a",
   "metadata": {
    "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import gdown\n",
    "import terratorch\n",
    "import albumentations\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule\n",
    "import warnings\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "os.environ[\"TENSORBOARD_PROXY_URL\"]= os.environ[\"NB_PREFIX\"]+\"/proxy/6006/\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b65b8e7cd7d65",
   "metadata": {},
   "source": [
    "3. Download the dataset from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad914cc-d34b-4e1a-8687-123bd0471164",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('granite-geospatial-biomass-dataset.zip'):\n",
    "    gdown.download(\"https://drive.google.com/file/d/1k-SuberK2iq1NpiP1e9puNp7RVlg7I-X\")\n",
    "    \n",
    "if not os.path.isdir('granite-geospatial-biomass-dataset/'):\n",
    "    with zipfile.ZipFile('granite-geospatial-biomass-dataset.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('granite-geospatial-biomass-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494",
   "metadata": {
    "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494"
   },
   "source": [
    "## AGB Dataset\n",
    "\n",
    "Lets start with analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3",
   "metadata": {
    "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3"
   },
   "outputs": [],
   "source": [
    "dataset_path = Path('granite-geospatial-biomass-dataset/granite-geospatial-biomass-dataset')\n",
    "!ls \"granite-geospatial-biomass-dataset/granite-geospatial-biomass-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84969a1f8bcae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"granite-geospatial-biomass-dataset/granite-geospatial-biomass-dataset/train_images/\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc",
   "metadata": {
    "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc"
   },
   "outputs": [],
   "source": [
    "datamodule = terratorch.datamodules.GenericNonGeoPixelwiseRegressionDataModule(\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    num_classes=2,\n",
    "    check_stackability = False,\n",
    "    # Define dataset paths \n",
    "    train_data_root=dataset_path / 'train_images/',\n",
    "    train_label_data_root=dataset_path / 'train_labels/',\n",
    "    val_data_root=dataset_path / 'val_images/',\n",
    "    val_label_data_root=dataset_path / 'val_labels/',\n",
    "    test_data_root=dataset_path / 'test_images/',\n",
    "    test_label_data_root=dataset_path / 'test_labels/',\n",
    "    \n",
    "    img_grep='*.tif',\n",
    "    label_grep='*.tif',\n",
    "    \n",
    "    train_transform=[\n",
    "        albumentations.D4(), # Random flips and rotation\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    ],\n",
    "    val_transform=None,  # Using ToTensor() by default\n",
    "    test_transform=None,\n",
    "        \n",
    "    # Define standardization values\n",
    "    means=[\n",
    "      547.36707,\n",
    "      898.5121,\n",
    "      1020.9082,\n",
    "      2665.5352,\n",
    "      2340.584,\n",
    "      1610.1407,\n",
    "    ],\n",
    "    stds=[\n",
    "      411.4701,\n",
    "      558.54065,\n",
    "      815.94025,\n",
    "      812.4403,\n",
    "      1113.7145,\n",
    "      1067.641,\n",
    "    ],\n",
    "    dataset_bands = [-1, \"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\", -1, -1, -1, -1],\n",
    "    output_bands = [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "    rgb_indices = [2, 1, 0],\n",
    "    no_data_replace=0,\n",
    "    no_label_replace=-1,\n",
    ")\n",
    "\n",
    "# Setup train and val datasets\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08644e71-d82f-426c-b0c1-79026fccb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datasets train split size\n",
    "train_dataset = datamodule.train_dataset\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7062ddc-a3b7-4378-898c-41abcdf2ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking datasets validation split size\n",
    "val_dataset = datamodule.val_dataset\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc29b1698dc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a few samples\n",
    "val_dataset.plot(val_dataset[0])\n",
    "val_dataset.plot(val_dataset[6])\n",
    "val_dataset.plot(val_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79",
   "metadata": {
    "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79"
   },
   "outputs": [],
   "source": [
    "# checking datasets testing split size\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a30ddef8ed5a",
   "metadata": {},
   "source": [
    "# Fine-tune Prithvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
   "metadata": {
    "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"output/agb/checkpoints/\",\n",
    "    mode=\"min\",\n",
    "    monitor=\"val/RMSE\", # Variable to monitor\n",
    "    filename=\"best-{epoch:02d}\",\n",
    ")\n",
    "\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=1, # Deactivate multi-gpu because it often fails in notebooks\n",
    "    precision='bf16-mixed',  # Speed up training\n",
    "    num_nodes=1,\n",
    "    logger=True,  # Uses TensorBoard by default\n",
    "    max_epochs=1, # For demos\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, pl.callbacks.RichProgressBar()],\n",
    "    default_root_dir=\"output/agb\",\n",
    "    detect_anomaly=True,\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = terratorch.tasks.PixelwiseRegressionTask(\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    model_args={\n",
    "        # Backbone\n",
    "        \"backbone\": \"prithvi_eo_v2_300\", # Model can be either prithvi_eo_v1_100, prithvi_eo_v2_300, prithvi_eo_v2_300_tl, prithvi_eo_v2_600, prithvi_eo_v2_600_tl\n",
    "        \"backbone_pretrained\": True,\n",
    "        \"backbone_num_frames\": 1, # 1 is the default value,\n",
    "        # \"backbone_img_size\": 224,\n",
    "        \"backbone_bands\": [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "        # \"backbone_coords_encoding\": [], # use [\"time\", \"location\"] for time and location metadata\n",
    "        \n",
    "        # Necks \n",
    "        \"necks\": [\n",
    "            {\n",
    "                \"name\": \"SelectIndices\",\n",
    "                # \"indices\": [2, 5, 8, 11] # indices for prithvi_eo_v1_100\n",
    "                \"indices\": [5, 11, 17, 23] # indices for prithvi_eo_v2_300\n",
    "                # \"indices\": [7, 15, 23, 31] # indices for prithvi_eo_v2_600\n",
    "            },\n",
    "            {\"name\": \"ReshapeTokensToImage\",},\n",
    "            {\"name\": \"LearnedInterpolateToPyramidal\"}            \n",
    "        ],\n",
    "        \n",
    "        # Decoder\n",
    "        \"decoder\": \"UNetDecoder\",\n",
    "        \"decoder_channels\": [512, 256, 128, 64],\n",
    "        # \"head_dropout\": 0.16194593880230534,\n",
    "        # \"head_final_act\": torch.nn.ReLU,\n",
    "        # \"head_learned_upscale_layers\": 2\n",
    "    },\n",
    "    \n",
    "    loss=\"rmse\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr=1e-3,\n",
    "    ignore_index=-1,\n",
    "    freeze_backbone=True, # Only to speed up fine-tuning\n",
    "    freeze_decoder=False,\n",
    "    plot_on_val=True,\n",
    "    # class_names=['no burned', 'burned']  # optionally define class names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe0ec00057c56dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output/multicrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff284062edfce308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13005a8c-5eff-431a-8412-3e71dd9f412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_path = \"output/agb/checkpoints/best-epoch=00.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3141059-db89-4bf2-8eb5-3024a6a0aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_and_visual_inspection(model, ckpt_path):\n",
    "\n",
    "    # let's run the model on the test set\n",
    "    trainer.test(model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "\n",
    "    # now we can use the model for predictions and plotting!\n",
    "    model = terratorch.tasks.PixelwiseRegressionTask.load_from_checkpoint(\n",
    "    ckpt_path,\n",
    "    model_factory=model.hparams.model_factory,\n",
    "    model_args=model.hparams.model_args,\n",
    "    )\n",
    "    \n",
    "    test_loader = datamodule.test_dataloader()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(test_loader))\n",
    "        images = datamodule.aug(batch)\n",
    "        images = batch[\"image\"].to(model.device)\n",
    "        \n",
    "        masks = batch[\"mask\"].numpy()\n",
    "    \n",
    "        preds = model(images).output\n",
    "    \n",
    "    for i in range(4):\n",
    "        sample = {key: batch[key][i] for key in batch}\n",
    "        sample[\"prediction\"] = preds[i].cpu()\n",
    "        sample[\"image\"] = sample[\"image\"].cpu()\n",
    "        sample[\"mask\"] = sample[\"mask\"].cpu()\n",
    "        test_dataset.plot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54bb3f-4e7b-4118-8c2e-b394dad6ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_and_visual_inspection(model, best_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5ca865-eb48-47e9-b1d8-9dc3154a36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_100_epoch_path = \"agb_best-epoch=68.ckpt\"\n",
    "\n",
    "if not os.path.isfile(best_ckpt_100_epoch_path):\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1ACjb4oWb2p_ZA87TQcuSWvCcB4_61fA-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ce152-37bc-4f44-a6d7-6097b7f539b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test_and_visual_inspection(model, best_ckpt_100_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54779ae510fefc8f",
   "metadata": {},
   "source": [
    "# Fine-tuning via CLI\n",
    "\n",
    "You might want to restart the session to free up GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8e91384bb8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fine-tuning\n",
    "!terratorch fit -c prithvi_v2_eo_300_tl_unet_agb.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac095bd-86ab-4a81-8ad9-d6acd4f4577d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
