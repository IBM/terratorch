# lightning.pytorch==2.1.1
seed_everything: 42
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  # precision: 16-mixed
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: tests/
      name: all_ecos_random
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 100
  max_epochs: 1
  check_val_every_n_epoch: 1
  log_every_n_steps: 20
  enable_checkpointing: true
  default_root_dir: tests/
data:
  class_path: GenericNonGeoSegmentationDataModule
  init_args:
    batch_size: 4
    num_workers: 4
    train_transform:
      - class_path: albumentations.HorizontalFlip
        init_args:
          p: 0.5      
      - class_path: albumentations.Rotate
        init_args:
          limit: 30
          border_mode: 0 # cv2.BORDER_CONSTANT
          value: 0
          # mask_value: 1
          p: 0.5
      - class_path: ToTensorV2
    dataset_bands:
      - [0, 11]
    output_bands:
      - [1, 3]
      - [4, 6]
    rgb_indices:
      - 2
      - 1
      - 0
    train_data_root: tests/resources/inputs_large
    train_label_data_root: tests/resources/labels_large
    val_data_root: tests/resources/inputs_large
    val_label_data_root: tests/resources/labels_large
    test_data_root: tests/resources/inputs_large
    test_label_data_root: tests/resources/labels_large 
    img_grep: "segmentation*input*.tif"
    label_grep: "segmentation*label*.tif"
    means:
    - 547.36707
    - 898.5121
    - 1020.9082
    - 2665.5352
    - 2340.584
    - 1610.1407
    stds:
    - 411.4701
    - 558.54065
    - 815.94025
    - 812.4403
    - 1113.7145
    - 1067.641
    no_label_replace: -1
    no_data_replace: 0
    num_classes: 2
model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_args:
      decoder: UperNetDecoder
      pretrained: true
      backbone: prithvi_eo_v2_600
        #backbone_pretrained_cfg_overlay:
        #file: tests/prithvi_swin_B.pt
        #backbone_drop_path_rate: 0.3
      # backbone_window_size: 8
      decoder_channels: 256
      in_channels: 6
      bands:
        - BLUE
        - GREEN
        - RED
        - NIR_NARROW
        - SWIR_1
        - SWIR_2
      num_frames: 1
      num_classes: 2
      head_dropout: 0.5708022831486758
    output_most_probable: false
    tiled_inference_on_testing: true
    path_to_record_metrics: ./
    loss: ce
    #aux_heads:
    #  - name: aux_head
    #    decoder: IdentityDecoder
    #    decoder_args:
    #      decoder_out_index: 2
    #      head_dropout: 0,5
    #      head_channel_list:
    #        - 64
    #      head_final_act: torch.nn.ReLU
    #aux_loss:
    #  aux_head: 0.4
    ignore_index: -1
    freeze_backbone: true
    freeze_decoder: false
    model_factory: PrithviModelFactory

    # uncomment this block for tiled inference
    tiled_inference_parameters:
       h_crop: 224 #128
       h_stride: 192 #128
       w_crop: 224 #128
       w_stride: 224 #128
       average_patches: true
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.00013524680528283027
    weight_decay: 0.047782217873995426
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss

